{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### PRACTICAL NO. 1\n"
      ],
      "metadata": {
        "id": "WKYndMVIG5eh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIM: Write a program and preprocess the data in python"
      ],
      "metadata": {
        "id": "y7fnSyPJHAdH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaRvqtW9Gzu5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "# Your dataset\n",
        "data = {\n",
        "'Country': ['India', 'Sri Lanka', 'China', 'Sri Lanka', 'China', 'India', 'Sri Lanka', 'India', 'China', 'India',\n",
        "'Sri Lanka', 'China', 'India', 'India', 'Sri Lanka'],\n",
        "'Age': [34, 22, 31, 29, 55, 24, 28, None, 51, 44, 21, 25, 33, 42, 33],\n",
        "'Salary': [92000, 25000, 74000, None, 98000, 30000, 40000, 60000, 89000, 78000, 20000, 30000,\n",
        "45000, 65000, 22000],\n",
        "'Purchased': ['Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "# Separate numerical and categorical columns\n",
        "numeric_features = ['Age', 'Salary']\n",
        "categorical_features = ['Country']\n",
        "# Define preprocessing steps\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "('imputer', SimpleImputer(strategy='mean')),\n",
        "('scaler', StandardScaler())])\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "transformers=[\n",
        "('num', numeric_transformer, numeric_features),\n",
        "('cat', categorical_transformer, categorical_features)])\n",
        "# Apply preprocessing to the data\n",
        "preprocessed_data = preprocessor.fit_transform(df)\n",
        "# Get feature names after one-hot encoding\n",
        "feature_names = numeric_features + list(preprocessor.named_transformers_['cat']\n",
        ".named_steps['onehot']\n",
        ".get_feature_names_out(categorical_features))\n",
        "# Convert preprocessed data back to a DataFrame\n",
        "preprocessed_df = pd.DataFrame(preprocessed_data, columns=feature_names)\n",
        "print(preprocessed_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Assuming you have your preprocessed data in preprocessed_df\n",
        "# Visualizing Age distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(preprocessed_df['Age'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "# Visualizing Salary distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(preprocessed_df['Salary'], bins=20, kde=True, color='salmon')\n",
        "plt.title('Distribution of Salary')\n",
        "plt.xlabel('Salary')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "# Visualizing relationship between Age and Salary\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='Age', y='Salary', data=preprocessed_df, color='green')\n",
        "plt.title('Relationship between Age and Salary')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Salary')\n",
        "plt.show()\n",
        "# Visualizing categorical data (Country after one-hot encoding)\n",
        "country_columns = [col for col in preprocessed_df.columns if 'Country' in col]\n",
        "country_data = preprocessed_df[country_columns]\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=country_data)\n",
        "plt.title('Count of Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lmLT_n8rHJj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 2"
      ],
      "metadata": {
        "id": "sOkTWn44ajq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a program to demonstrate various operations related to tensor, matrix & vector."
      ],
      "metadata": {
        "id": "6FkeK4E3aoHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "print(a)\n"
      ],
      "metadata": {
        "id": "n7DZvyKwadHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b=np.ones((3,3))\n",
        "print(b)\n"
      ],
      "metadata": {
        "id": "drLsTVg7avFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum=np.add(a,b)\n",
        "print(sum)\n"
      ],
      "metadata": {
        "id": "uFCe9ZNFa9pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff=np.subtract(a,b)\n",
        "print(diff)\n"
      ],
      "metadata": {
        "id": "fLI-C0ssa_iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mul=np.multiply(a,b)\n",
        "print(mul)\n"
      ],
      "metadata": {
        "id": "IcMnzk3mbBKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "m=tf.constant([[1,2,3],[4,5,6],[7,8,9]], shape=(3,3))\n",
        "print(m)\n"
      ],
      "metadata": {
        "id": "eMiJEowIbCwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=tf.constant([[10,20,30],[40,50,60],[70,80,90]],shape=(3,3))\n",
        "print(n)"
      ],
      "metadata": {
        "id": "0cB3hcqNbFgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add1=tf.add(m,n)\n",
        "add1\n"
      ],
      "metadata": {
        "id": "1v8DCbWfbIod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mul1=tf.multiply(n,m)\n",
        "mul1"
      ],
      "metadata": {
        "id": "wl1RC6AXbWQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mat=tf.matmul(m,n)\n",
        "mat"
      ],
      "metadata": {
        "id": "A9CIF0WhbbLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.reduce_max(a))\n",
        "print(tf.reduce_max(b))\n"
      ],
      "metadata": {
        "id": "_oM_1PLbbhMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.argmax(a))"
      ],
      "metadata": {
        "id": "NZO4ZnqZbj3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=tf.ones([3,3])\n",
        "a"
      ],
      "metadata": {
        "id": "2nLkUbmQbmsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.nn.softmax(a)\n"
      ],
      "metadata": {
        "id": "_sdvJVY5bpcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=tf.zeros([3,3])\n",
        "a"
      ],
      "metadata": {
        "id": "zUvaHcvobsSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A=tf.constant([[1,2],[3,4]])\n",
        "B=tf.reshape(A,[4,1])\n",
        "B"
      ],
      "metadata": {
        "id": "AzUFz-mCbu3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=tf.range(3,19,3)\n",
        "a"
      ],
      "metadata": {
        "id": "m-vp0TKob04h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor=tf.constant([[1,2,3],[4,5,6]])\n",
        "tf.zeros_like(tensor)"
      ],
      "metadata": {
        "id": "VDbaukhCb413"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.shuffle(tensor,seed=2,name=None)\n"
      ],
      "metadata": {
        "id": "Ukic9qhGb9ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PRACTICAL NO. 3"
      ],
      "metadata": {
        "id": "sitCmSmicKFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIM: Perfrom the following matrix operation in python:"
      ],
      "metadata": {
        "id": "gwNOgqZMcMbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Finding eigen values and eigen vectors\n"
      ],
      "metadata": {
        "id": "-po26mbCcTNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 finding eigen values and eigen vectors\n",
        "import numpy as np\n",
        "# Define your matrix\n",
        "matrix = np.array([[1, 2, 3],\n",
        "[4, 5, 6],\n",
        "[7,8, 9]])\n",
        "# Find eigenvalues and eigenvectors\n",
        "eigenvalues, eigenvectors = np.linalg.eig(matrix)\n",
        "print(matrix)\n",
        "# Print the results\n",
        "print(\"Eigenvalues:\")\n",
        "print(eigenvalues)\n",
        "print(\"\\nEigenvectors:\")\n",
        "print(eigenvectors)"
      ],
      "metadata": {
        "id": "XgySolS3cFAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 Check for linear dependent and linear independent"
      ],
      "metadata": {
        "id": "kb4IQ3gCca6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Define your vectors as rows of a matrix\n",
        "vectors_matrix = np.array([[1, 0, 2, 1],\n",
        "[3, 1, 2, 1],\n",
        "[4, 6, 2, 4],\n",
        "[-6, 0, -3, 0]])\n",
        "# Check the rank of the matrix\n",
        "rank = np.linalg.matrix_rank(vectors_matrix)\n",
        "# Determine linear dependence or independence\n",
        "if rank == vectors_matrix.shape[0]:\n",
        "    print(\"Vectors are linearly independent.\")\n",
        "else:\n",
        "    print(\"Vectors are linearly dependent.\")"
      ],
      "metadata": {
        "id": "z7F5pHj8cX5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 Perform matrix transpose\n"
      ],
      "metadata": {
        "id": "7qnX_rG0clLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Define your matrix\n",
        "matrix = np.array([[1, 2, 3],\n",
        "[4, 5, 6],\n",
        "[7, 8, 9]])\n",
        "# Transpose the matrix\n",
        "transpose_matrix = np.transpose(matrix)\n",
        "# Alternatively, you can use the T attribute\n",
        "# transpose_matrix = matrix.T\n",
        "# Print the original and transposed matrices\n",
        "print(\"Original Matrix:\")\n",
        "print(matrix)\n",
        "print(\"\\nTransposed Matrix:\")\n",
        "print(transpose_matrix)"
      ],
      "metadata": {
        "id": "sIPdZO1pceMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 Perform diagonal matrix"
      ],
      "metadata": {
        "id": "n3uVlzr7csmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Define a list or array of diagonal elements\n",
        "diagonal_elements = [[1, 2, 3],\n",
        "[4, 5, 6],\n",
        "[7, 8, 9]]\n",
        "# Create a diagonal matrix\n",
        "diagonal_matrix = np.diag(diagonal_elements)\n",
        "# Print the diagonal matrix\n",
        "print(\"Diagonal Matrix:\")\n",
        "print(diagonal_matrix)"
      ],
      "metadata": {
        "id": "5p7tWD4KcpKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 triangular marix\n"
      ],
      "metadata": {
        "id": "QiXm6nS-c9_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lower triangle\n",
        "import numpy as np\n",
        "# Define a matrix\n",
        "matrix = np.array([[1, 2, 2],\n",
        "[1, 3, -1],\n",
        "[-3, -5, 4]])\n",
        "# Print the original matrix\n",
        "print(\"Original Matrix:\")\n",
        "print(matrix)\n",
        "# Extract the lower triangular part\n",
        "lower_triangular_matrix = np.triu(matrix)\n",
        "# Print the lower triangular matrix\n",
        "print(\"\\nLower Triangular Matrix:\")\n",
        "print(lower_triangular_matrix)\n"
      ],
      "metadata": {
        "id": "3Q9kqfrkc4JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 Perform orthogonal matrix using numpy modules\n"
      ],
      "metadata": {
        "id": "NY_T0ubhdFBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Define a square matrix\n",
        "matrix = np.array([[1, 0],\n",
        "[0, -1]])\n",
        "# Perform QR decomposition\n",
        "q, r = np.linalg.qr(matrix)\n",
        "# Check if q is an orthogonal matrix\n",
        "is_orthogonal = np.allclose(np.dot(q, q.T), np.eye(matrix.shape[0]))\n",
        "# Print the original and orthogonal matrices\n",
        "print(\"Original Matrix:\")\n",
        "print(matrix)\n",
        "print(\"\\nOrthogonal Matrix:\")\n",
        "print(q)\n"
      ],
      "metadata": {
        "id": "n3LJ91xTdB4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PRACTICAL NO. 4"
      ],
      "metadata": {
        "id": "NBAmKjdMdOE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIM: Solve the XOR problem using deep feed forward network"
      ],
      "metadata": {
        "id": "tap6Qm9mdQ2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "# Define the XOR data\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = np.array([[0], [1], [1], [0]])\n",
        "# Create a deep feed-forward neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X, Y, epochs=100, verbose=2)\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X, Y)\n",
        "print(f'\\nLoss: {loss}, Accuracy: {accuracy}')\n",
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "rounded_predictions = np.round(predictions)\n",
        "print('Predictions:', rounded_predictions.flatten())"
      ],
      "metadata": {
        "id": "HNaM_l53dIsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PRACTICAL NO. 5"
      ],
      "metadata": {
        "id": "RIk28jN_dX-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIM: Performing Convolutional operation using CNN"
      ],
      "metadata": {
        "id": "SV5dvSnLdbFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "from keras.layers import Convolution2D, MaxPooling2D,Activation\n",
        "from keras.models import Sequential\n",
        "from numpy import asarray\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "#loading & displaying name\n",
        "img=cv2.imread('/content/mypic (pdf.io).jpg',cv2.IMREAD_GRAYSCALE)\n",
        "plt.imshow(img,cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1JXHQIeOdas_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape\n"
      ],
      "metadata": {
        "id": "XwTOPrO8dUQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshaping image shape\n",
        "img_batch=img.reshape(1,img.shape[0],img.shape[1],1)\n",
        "#accessing image batch shape\n",
        "img_batch.shape"
      ],
      "metadata": {
        "id": "_GtW3bE0dr_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining sequential model\n",
        "img_batch.shape[1:]\n",
        "model1=Sequential()\n",
        "#adding convolutional layer\n",
        "model1.add(Convolution2D(1,(15,15),padding='valid',input_shape=img_batch.shape[1:]))\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "EQORhhUdduGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting with model\n",
        "conv_img=model1.predict(img_batch)\n"
      ],
      "metadata": {
        "id": "XTgEH1cvdxyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_img.shape"
      ],
      "metadata": {
        "id": "C2iZ7DUnd57T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshaping predicted image for display\n",
        "conv_img_show = conv_img.reshape(conv_img.shape[1], conv_img.shape[2])\n",
        "plt.imshow(conv_img_show, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jdr0v2j1d6ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining sequential model\n",
        "img_batch.shape[1:]\n",
        "model2=Sequential()\n",
        "#convutional layer\n",
        "model2.add(Convolution2D(1,(3,3),padding='valid',input_shape=img_batch.shape[1:]))\n",
        "#random weight initialization\n",
        "model2.add(Activation('relu'))\n",
        "#predicting with model2\n",
        "conv_img=model2.predict(img_batch)\n",
        "#checking\n",
        "conv_img.shape\n",
        "#reshaping predicted image for display\n",
        "conv_img_show = conv_img.reshape(conv_img.shape[1], conv_img.shape[2])\n",
        "plt.imshow(conv_img_show, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EIHLOUn_d94X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model4\n",
        "img_batch.shape[1:]\n",
        "model4=Sequential()\n",
        "model4.add(Convolution2D(1,(15,15),padding='valid',input_shape=img_batch.shape[1:]))\n",
        "#random weight initialization\n",
        "model4.add(Activation('relu'))\n",
        "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#predicting with model2\n",
        "conv_img=model4.predict(img_batch)\n",
        "#checking\n",
        "conv_img.shape\n",
        "#reshaping predicted image for display\n",
        "conv_img_show = conv_img.reshape(conv_img.shape[1], conv_img.shape[2])\n",
        "plt.imshow(conv_img_show, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fQQ7TVBKeDzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PRACTICAL NO. 6"
      ],
      "metadata": {
        "id": "cGESI8WveKqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a program to implement CNNâ€™s various layers."
      ],
      "metadata": {
        "id": "Iw0n7KXheNr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
        "\n",
        "# Split training set into training and validation sets\n",
        "x_validate, x_train = x_train_full[:500], x_train_full[500:]\n",
        "y_validate, y_train = y_train_full[:500], y_train_full[500:]\n",
        "\n",
        "class_names = [\"T-shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "# Define the model\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "hidden1 = model.layers[1]\n",
        "hidden1_weights = hidden1.get_weights()\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_validate, y_validate))\n"
      ],
      "metadata": {
        "id": "E716kLjleR4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PRACTICAL NO. 7"
      ],
      "metadata": {
        "id": "yXsgU4fpe6ws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIM: Write a program to display & plot various performance parameters related to CNN."
      ],
      "metadata": {
        "id": "oLpKo2BUe93b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Select a mini subset of the dataset\n",
        "mini_train_images = train_images[:1000]\n",
        "mini_train_labels = train_labels[:1000]\n",
        "mini_test_images = test_images[:500]\n",
        "mini_test_labels = test_labels[:500]\n",
        "\n",
        "# Assuming you have your model prepared\n",
        "\n",
        "# Train the model on mini dataset\n",
        "history = model.fit(mini_train_images, mini_train_labels, epochs=10, validation_data=(mini_test_images, mini_test_labels))\n",
        "\n",
        "# Visualize accuracy and loss curves\n",
        "plt.plot(history.history['accuracy'], label=\"Accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val loss')\n",
        "\n",
        "# Customize plot for clarity\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy/Loss')\n",
        "plt.title('Model Training and Validation Performance')\n",
        "plt.grid(True)  # Add grid lines for better readability\n",
        "plt.ylim(0, 1)  # Set appropriate y-axis limits for accuracy\n",
        "\n",
        "# Evaluate test data performance on mini dataset\n",
        "test_loss, test_acc = model.evaluate(mini_test_images, mini_test_labels)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc * 100)\n",
        "\n",
        "# Optionally display the plot (if desired)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7_9yKM7feX2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PRACTICAL NO. 8"
      ],
      "metadata": {
        "id": "GHFrZKIAiW1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of CNN to predict number from number images"
      ],
      "metadata": {
        "id": "cxaKAAGViYxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "(X_train,Y_train), (X_test, Y_test) =mnist.load_data()\n",
        "plt.imshow(X_train[2])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iHwtCB0efDfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0].shape)\n",
        "X_train = X_train.reshape(60000, 28, 28, 1)\n",
        "X_train -= X_train.reshape(60000, 28, 28, 1)\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)"
      ],
      "metadata": {
        "id": "FA_fROcpicxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train=to_categorical (Y_train)\n",
        "Y_test=to_categorical (Y_test)\n",
        "Y_train[0]\n",
        "print(Y_train[0])"
      ],
      "metadata": {
        "id": "nWLJsZiuihLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D (64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D (32, kernel_size=3, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense (10, activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.fit(X_train,Y_train, validation_data=(X_test,Y_test), epochs=1)\n",
        "print(model.predict(X_test[:4]))\n",
        "print(Y_test[:4])"
      ],
      "metadata": {
        "id": "N0X_lmF9ilNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practical 9"
      ],
      "metadata": {
        "id": "_gALNlYljzUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a program to implement RNN"
      ],
      "metadata": {
        "id": "XCWc7fEsj7Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.optimizers import Adam\n",
        "# Load and preprocess the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "# Reshape input data for LSTM\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1:]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))\n",
        "# Evaluate the model\n",
        "model.evaluate(X_test, y_test, verbose=0)"
      ],
      "metadata": {
        "id": "iKU3c1x_ioz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_R2JPT6kBIc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}